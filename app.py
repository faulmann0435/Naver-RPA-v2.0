"""
Sokcho Order Processing System v14.4
- Quantity Display Lock: prevents double quantity stamping (e.g., "x2 x2")
- GROUP_MULTIPLY: append (x{Qty}) only, no param word repeat
- Config: load_config_local, List-based, Session State
"""
import re
from datetime import datetime
from io import BytesIO
from pathlib import Path

import pandas as pd
import streamlit as st

try:
    import msoffcrypto
    HAS_MSOFFCRYPTO = True
except ImportError:
    HAS_MSOFFCRYPTO = False

# --- Column names (order data) ---
HEADER_KEYWORDS = ["ìƒí’ˆëª…", "ìˆ˜ì·¨ì¸ëª…", "ì˜µì…˜ì •ë³´"]
FILTER_PHRASE = "ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ë¡œ 'ì—‘ì…€ ì¼ê´„ë°œì†¡' ì²˜ë¦¬í•˜ëŠ” ë°©ë²•"
QTY_COLUMN_INDEX = 12
DEFAULT_PHONE_COL = "ìˆ˜ì·¨ì¸ì—°ë½ì²˜1"
ALT_PHONE_COL = "êµ¬ë§¤ìì—°ë½ì²˜"


def _strip_columns(df):
    df.columns = [str(c).strip() for c in df.columns]
    return df


def find_header_row(preview_df):
    for i in range(len(preview_df)):
        row_vals = preview_df.iloc[i].astype(str).str.strip().tolist()
        row_text = " ".join(row_vals)
        if all(kw in row_text for kw in HEADER_KEYWORDS):
            return i
    return 0


def ensure_quantity_column(df):
    if "ìˆ˜ëŸ‰" in df.columns:
        return df
    if df.shape[1] <= QTY_COLUMN_INDEX:
        return df
    df.rename(columns={df.columns[QTY_COLUMN_INDEX]: "ìˆ˜ëŸ‰"}, inplace=True)
    return df


# ============== Config Loader (v14.3: load_config_local + cache) ==============

@st.cache_data(ttl=3600)
def load_config_local(config_path: str, _password: str = None, _cache_key: str = None):
    """
    Load config.xlsx with password support. Uses msoffcrypto if encrypted.
    Returns: dict with keys ['ProductRoute', 'OptionRules', 'OutputLayout']
    _cache_key: pass file mtime/size to invalidate cache when file changes.
    """
    path = Path(config_path).resolve()
    if not path.exists():
        raise FileNotFoundError(
            f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {path!s}\n"
            "config.xlsxë¥¼ ì•±ê³¼ ê°™ì€ í´ë”ì— ë‘ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )
    password = _password if _password and str(_password).strip() else None
    # _cache_key used only for cache invalidation (not for decryption)

    raw = path.read_bytes()
    if HAS_MSOFFCRYPTO:
        bio = BytesIO(raw)
        office_file = msoffcrypto.OfficeFile(bio)
        if office_file.is_encrypted():
            if not (password and str(password).strip()):
                raise ValueError("ì„¤ì • íŒŒì¼ì´ ì•”í˜¸í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
            try:
                office_file.load_key(password=str(password).strip())
                decrypted = BytesIO()
                office_file.decrypt(decrypted)
                decrypted.seek(0)
                raw = decrypted.getvalue()
            except Exception as e:
                raise ValueError("ì„¤ì • íŒŒì¼ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.") from e

    xl = pd.ExcelFile(BytesIO(raw))
    required_sheets = ["ProductRoute", "OptionRules", "OutputLayout"]
    missing = [s for s in required_sheets if s not in xl.sheet_names]
    if missing:
        raise ValueError(f"ì„¤ì • ì‹œíŠ¸ ëˆ„ë½: {missing}. í•„ìš”: {required_sheets}")

    product_route = pd.read_excel(xl, sheet_name="ProductRoute")
    option_rules = pd.read_excel(xl, sheet_name="OptionRules")
    output_layout = pd.read_excel(xl, sheet_name="OutputLayout")

    _strip_columns(product_route)
    _strip_columns(option_rules)
    _strip_columns(output_layout)

    _debug_option_raw_headers = option_rules.columns.tolist()

    def _norm_product_route(df):
        rename_map = {}
        for col in df.columns:
            c = str(col).strip()
            if "ìš°ì„ ìˆœìœ„" in c:
                rename_map[col] = "Priority"
            elif "í‚¤ì›Œë“œ" in c:
                rename_map[col] = "Keyword"
            elif "ì–‘ì‹ëª…ì¹­" in c:
                rename_map[col] = "TargetVendorID"
        return df.rename(columns=rename_map) if rename_map else df

    def _norm_option_rules(df):
        rename_map = {}
        for col in df.columns:
            c = str(col).strip()
            if "ìˆœì„œ" in c:
                rename_map[col] = "Order"
            elif "ì„¤ì •ê°’" in c or "Parameter" in c:
                rename_map[col] = "Parameter"
            elif "ëª…ë ¹" in c or "Action" in c or "ActionType" in c:
                rename_map[col] = "ActionType"
            elif "ì ìš©ëŒ€ìƒ" in c or "Target" in c or "TargetKeyword" in c:
                rename_map[col] = "TargetKeyword"
            elif "ì–‘ì‹" in c or "Apply" in c or "ì–‘ì‹ëª…ì¹­" in c:
                rename_map[col] = "ApplyTo"
            elif "Description" in c or "ì„¤ëª…" in c:
                rename_map[col] = "Description"
        return df.rename(columns=rename_map) if rename_map else df

    def _norm_output_layout(df):
        rename_map = {}
        for col in df.columns:
            c = str(col).strip()
            if "ì–‘ì‹ëª…ì¹­" in c:
                rename_map[col] = "VendorID"
            elif "íŒŒì¼ëª…" in c:
                rename_map[col] = "FilePrefix"
            elif "ì—´" in c:
                rename_map[col] = "ExcelCol"
            elif "í—¤ë”ëª…" in c:
                rename_map[col] = "HeaderName"
            elif "ë§¤í•‘ë°ì´í„°" in c:
                rename_map[col] = "SourceCol"
            elif "ê³ ì •ê°’" in c:
                rename_map[col] = "HardcodedValue"
        return df.rename(columns=rename_map) if rename_map else df

    def _strip_all_strings(df):
        for col in df.columns:
            if df[col].dtype == object or df[col].dtype.kind == "O":
                df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)
        return df

    product_route = _norm_product_route(product_route)
    option_rules = _norm_option_rules(option_rules)
    output_layout = _norm_output_layout(output_layout)

    product_route = _strip_all_strings(product_route)
    option_rules = _strip_all_strings(option_rules)
    output_layout = _strip_all_strings(output_layout)

    # Data Cleaning: Parameter string, ApplyTo Uppercase
    if "Parameter" in option_rules.columns:
        option_rules["Parameter"] = option_rules["Parameter"].astype(str)
        option_rules["Parameter"] = option_rules["Parameter"].replace(["nan", "NaN", "None", "<NA>"], "")
        option_rules["Parameter"] = option_rules["Parameter"].str.strip()
    else:
        option_rules["Parameter"] = ""
    if "ApplyTo" in option_rules.columns:
        option_rules["ApplyTo"] = option_rules["ApplyTo"].fillna("").astype(str).str.strip().str.upper()
    else:
        option_rules["ApplyTo"] = ""
    if "TargetKeyword" in option_rules.columns:
        option_rules["TargetKeyword"] = option_rules["TargetKeyword"].fillna("").astype(str).str.strip()
    else:
        option_rules["TargetKeyword"] = ""

    _debug_option_renamed_headers = option_rules.columns.tolist()

    for name, df in [("ProductRoute", product_route), ("OptionRules", option_rules), ("OutputLayout", output_layout)]:
        if df.empty:
            raise ValueError(f"ì„¤ì • ì‹œíŠ¸ '{name}'ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    for col in ["Priority", "Keyword", "TargetVendorID"]:
        if col not in product_route.columns:
            raise ValueError(f"ProductRouteì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    product_route = product_route.sort_values("Priority", ascending=True).reset_index(drop=True)

    for col in ["Order", "ApplyTo", "TargetKeyword", "ActionType"]:
        if col not in option_rules.columns:
            raise ValueError(f"OptionRulesì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    if "Parameter" not in option_rules.columns:
        option_rules["Parameter"] = ""
    if "Description" not in option_rules.columns:
        option_rules["Description"] = ""
    option_rules = option_rules.sort_values("Order", ascending=True).reset_index(drop=True)

    for col in ["VendorID", "FilePrefix", "ExcelCol", "HeaderName"]:
        if col not in output_layout.columns:
            raise ValueError(f"OutputLayoutì— '{col}' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    if "SourceCol" not in output_layout.columns:
        output_layout["SourceCol"] = ""
    if "HardcodedValue" not in output_layout.columns:
        output_layout["HardcodedValue"] = ""

    return {
        "ProductRoute": product_route,
        "OptionRules": option_rules,
        "OutputLayout": output_layout,
        "_debug_OptionRules_raw_headers": _debug_option_raw_headers,
        "_debug_OptionRules_renamed_headers": _debug_option_renamed_headers,
    }


# ============== Load Order File ==============

def _get_excel_bytes(uploaded_file, password=None):
    raw = uploaded_file.read()
    if not raw:
        raise ValueError("íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    if not HAS_MSOFFCRYPTO:
        return raw
    bio = BytesIO(raw)
    office_file = msoffcrypto.OfficeFile(bio)
    if not office_file.is_encrypted():
        return raw
    if not (password and str(password).strip()):
        raise ValueError("ì—‘ì…€ íŒŒì¼ì´ ì•”í˜¸í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    try:
        office_file.load_key(password=str(password).strip())
        decrypted = BytesIO()
        office_file.decrypt(decrypted)
        decrypted.seek(0)
        return decrypted.getvalue()
    except Exception as e:
        err_msg = str(e).lower()
        if "invalidkey" in type(e).__name__.lower() or "password" in err_msg or "decrypt" in err_msg:
            raise ValueError("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.") from e
        raise ValueError(f"ì•”í˜¸ í•´ì œ ì‹¤íŒ¨: {e}") from e


def load_excel(uploaded_file, password=None):
    file_name = (uploaded_file.name or "").lower()
    if not file_name.endswith(".xlsx"):
        raise ValueError("ì—‘ì…€ íŒŒì¼(.xlsx)ì´ ì•„ë‹™ë‹ˆë‹¤.")
    raw_bytes = _get_excel_bytes(uploaded_file, password=password)
    preview = pd.read_excel(BytesIO(raw_bytes), header=None, nrows=20)
    header_idx = find_header_row(preview)
    df = pd.read_excel(BytesIO(raw_bytes), header=header_idx)
    _strip_columns(df)
    ensure_quantity_column(df)
    return df


def read_csv_with_encoding(file):
    encodings = ("utf-8-sig", "utf-8", "cp949", "euc-kr")
    last_err = None
    for enc in encodings:
        try:
            file.seek(0)
            preview = pd.read_csv(file, encoding=enc, header=None, nrows=20)
            file.seek(0)
            header_idx = find_header_row(preview)
            file.seek(0)
            df = pd.read_csv(file, encoding=enc, header=header_idx)
            _strip_columns(df)
            ensure_quantity_column(df)
            return df
        except Exception as e:
            last_err = e
    raise ValueError(f"CSV ì¸ì½”ë”© íŒë³„ ì‹¤íŒ¨. {last_err}")


# ============== Step B: Routing ==============

def route_vendor(df, product_route):
    product_route = product_route.sort_values("Priority", ascending=True).reset_index(drop=True)
    name_col = "ìƒí’ˆëª…" if "ìƒí’ˆëª…" in df.columns else None
    option_col = "ì˜µì…˜ì •ë³´" if "ì˜µì…˜ì •ë³´" in df.columns else None
    if not name_col:
        df = df.copy()
        df["_VendorID"] = "Unclassified"
        return df

    def search_vendor(row):
        name = str(row.get(name_col, "") or "")
        option = str(row.get(option_col, "") or "") if option_col else ""
        search_text = (name + " " + option).strip()
        fallback_vendor = None
        for _, r in product_route.iterrows():
            keywords_raw = str(r.get("Keyword", "") or "").strip()
            if not keywords_raw:
                continue
            keywords = [k.strip() for k in keywords_raw.split(",") if k.strip()]
            for kw in keywords:
                if str(kw).upper() == "DEFAULT":
                    fallback_vendor = str(r.get("TargetVendorID", "") or "").strip()
                    break
                if kw in search_text:
                    return str(r.get("TargetVendorID", "") or "").strip()
        return fallback_vendor if fallback_vendor else "Unclassified"

    df = df.copy()
    df["_VendorID"] = df.apply(search_vendor, axis=1)
    return df


# ============== Step C: Option Rules (Logic Engine) ==============

def _safe_int(x, default=1):
    try:
        v = int(x)
        return v if v > 0 else default
    except (TypeError, ValueError):
        return default


def _apply_remove_text(text, param):
    if not param or not str(param).strip():
        return text
    keywords = [k.strip() for k in str(param).split(",") if k.strip()]
    for kw in keywords:
        text = str(text).replace(kw, "")
    return text


def _apply_remove_regex(text, param):
    if not param or not str(param).strip():
        return text
    try:
        return re.sub(str(param).strip(), "", str(text))
    except re.error:
        return text


def _apply_mask_text(text, param):
    if not param or not str(param).strip():
        return text
    t = str(text)
    keywords = [k.strip() for k in str(param).split(",") if k.strip()]
    for kw in keywords:
        t = t.replace(kw, f"__MASK__{kw}__")
    return t


def _apply_unmask_text(text, param):
    return re.sub(r"__MASK__(.+?)__", r"\1", str(text))


def _apply_convert_weight_range_fix(text, qty, calculated_weight_ref):
    """
    One-Shot Safe: Find weight patterns. If range (e.g. 800g-1kg), take MAX only.
    weight_kg = MaxValue_kg * RowQty. Remove weight text AND immediately append " {weight_kg}kg".
    Caller must check _weight_calculated lock before invoking (prevents double count).
    """
    qty = _safe_int(qty, 1)
    pattern = re.compile(r"(\d+(?:\.\d+)?)\s*(g|kg|G|KG)", re.IGNORECASE)
    matches = list(pattern.finditer(str(text)))
    if not matches:
        return text
    values_kg = []
    for m in matches:
        num = float(m.group(1))
        u = (m.group(2) or "g").lower()
        kg = num / 1000.0 if u == "g" else num
        values_kg.append(kg)
    max_kg = max(values_kg)
    weight_kg = max_kg * qty
    calculated_weight_ref[0] += weight_kg
    cleaned = pattern.sub("", str(text)).strip()
    ws = f"{int(weight_kg)}kg" if weight_kg == int(weight_kg) else f"{weight_kg:.1f}kg"
    return (cleaned + " " + ws).strip()


def _apply_calc_unit(text, param, qty):
    """
    Precision Mode: Find (\\d+)\\s*{Parameter}, replace with NewNum = FoundNum * RowQty, keep unit.
    Example: "10ë§ˆë¦¬" (Qty 3) -> "30ë§ˆë¦¬".
    """
    qty = _safe_int(qty, 1)
    unit = str(param).strip() if param else ""
    if not unit:
        return text
    pattern = re.compile(r"(\d+)\s*" + re.escape(unit))
    def repl(m):
        n = int(m.group(1)) * qty
        return f"{n}{unit}"
    return pattern.sub(repl, str(text))


def _apply_group_multiply(text, param, qty, search_in=None):
    """
    If Parameter exists in search_in (or text if search_in not provided), append (x{RowQty}) to text only.
    search_in: optional string to check for param (e.g. product+option); when set, append is still applied to text.
    Example: text="1íŒ©", search_in="Squid 1íŒ©", param="Squid" -> "1íŒ© (x2)".
    """
    qty = _safe_int(qty, 1)
    kw = str(param).strip() if param else ""
    if not kw:
        return text
    check_against = str(search_in).strip() if search_in is not None else str(text)
    if kw not in check_against:
        return text
    return (str(text).strip() + f" (x{qty})").strip()


def _apply_append_suffix(text, param):
    if not param:
        return text
    return (str(text).strip() + " " + str(param).strip()).strip()


def _apply_prepend_text(text, param):
    """Prepend Parameter to text. Always apply (no lock)."""
    if not param or not str(param).strip():
        return text
    return (str(param).strip() + " " + str(text).strip()).strip()


def _apply_append_qty_unit(text, param, qty):
    """
    Direct Append (Squid Logic): Ignore weight/content, append "Qty + Unit".
    Example: Qty=3, Parameter="íŒ©" -> Appends " 3íŒ©". Result: "Squid 3íŒ©".
    """
    qty = _safe_int(qty, 1)
    unit = str(param).strip() if param else "ê°œ"
    return (str(text).strip() + f" {qty}{unit}").strip()


def _apply_format_qty_single_stamp(text, param, qty, qty_display_lock_ref):
    """
    Single Stamp: If not qty_display_lock, append format (e.g. x{qty}ê°œ), set lock = True.
    """
    if qty_display_lock_ref[0]:
        return text
    qty = _safe_int(qty, 1)
    if not param or not str(param).strip():
        fmt = f" x{qty}ê°œ"
    else:
        fmt = str(param).strip().replace("{qty}", str(qty))
        if "{qty}" not in str(param):
            fmt = f" x{qty}ê°œ"
    qty_display_lock_ref[0] = True
    return (str(text).strip() + " " + fmt).strip()


def _apply_replace_regex_sub(text, param):
    """
    REPLACE_REGEX_SUB: Split Parameter by '///' -> pattern, replacement.
    Apply re.sub(pattern, replacement, text).
    Example: '^.*Octopus.*$ /// (Steamed)' replaces matching line with '(Steamed)'.
    """
    if not param or not str(param).strip():
        return text
    s = str(param).strip()
    if "///" in s:
        parts = s.split("///", 1)
        pattern, repl = parts[0].strip(), parts[1].strip()
    elif "||" in s:
        pattern, repl = s.split("||", 1)[0].strip(), s.split("||", 1)[1].strip()
    else:
        pattern, repl = s, ""
    try:
        return re.sub(pattern, repl, str(text))
    except re.error:
        return text


def apply_option_rules(row, option_rules, name_col="ìƒí’ˆëª…", option_col="ì˜µì…˜ì •ë³´", qty_col="ìˆ˜ëŸ‰", row_index=None, debug_log=None):
    current_vendor = str(row.get("_VendorID", "") or "").strip().upper()
    product = str(row.get(name_col, "") or "").strip()
    raw_option = row.get(option_col, "")
    if pd.isna(raw_option):
        raw_option = ""
    # text = option only (modify target); full_context = product + option (for keyword search only)
    text = str(raw_option).strip()
    full_context = f"{product} {text}".strip()
    qty = _safe_int(row.get(qty_col, 1), 1)
    calculated_weight = 0.0
    weight_calculated = False  # One-Shot Lock: prevents double CONVERT_WEIGHT application
    qty_display_lock = False   # v14.4: prevents double quantity suffix (x2 x2)
    calculated_weight_ref = [calculated_weight]
    weight_calculated_ref = [weight_calculated]
    qty_display_lock_ref = [qty_display_lock]
    do_log = debug_log is not None and row_index is not None and row_index < 5

    for rule_idx, (_, rule) in enumerate(option_rules.iterrows(), start=1):
        rule_vendor = rule.get("ApplyTo", "") or ""
        rule_target = rule.get("TargetKeyword", "") or ""
        action = str(rule.get("ActionType", "") or "").strip().upper()
        param = rule.get("Parameter", "") or ""

        if rule_vendor != "ALL" and rule_vendor != current_vendor:
            if do_log:
                debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: {action}, Param: {repr(param)[:50]}) -> Matched? NO (ApplyTo)")
            continue
        if rule_target != "ALL" and rule_target not in full_context:
            if do_log:
                debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: {action}, Param: {repr(param)[:50]}) -> Matched? NO (TargetKeyword)")
            continue

        # CONVERT_WEIGHT One-Shot Lock: skip if already calculated for this row
        if action == "CONVERT_WEIGHT":
            if weight_calculated_ref[0]:
                if do_log:
                    debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: CONVERT_WEIGHT) -> SKIP (lock)")
                continue
            text = _apply_convert_weight_range_fix(text, qty, calculated_weight_ref)
            weight_calculated_ref[0] = True
        elif action == "REMOVE_TEXT":
            text = _apply_remove_text(text, param)
        elif action == "REMOVE_REGEX":
            text = _apply_remove_regex(text, param)
        elif action == "REPLACE_REGEX_SUB":
            text = _apply_replace_regex_sub(text, param)
        elif action == "MASK_TEXT":
            text = _apply_mask_text(text, param)
        elif action == "UNMASK_TEXT":
            text = _apply_unmask_text(text, param)
        elif action == "CALC_UNIT":
            text = _apply_calc_unit(text, param, qty)
        elif action == "APPEND_QTY_UNIT":
            if qty_display_lock_ref[0]:
                if do_log:
                    debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: APPEND_QTY_UNIT) -> SKIP (qty_display_lock)")
                continue
            text = _apply_append_qty_unit(text, param, qty)
            qty_display_lock_ref[0] = True
        elif action == "GROUP_MULTIPLY":
            if qty_display_lock_ref[0]:
                if do_log:
                    debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: GROUP_MULTIPLY) -> SKIP (qty_display_lock)")
                continue
            # Trigger if param in full_context; append (xQty) to text (option only)
            text = _apply_group_multiply(text, param, qty, search_in=full_context)
            qty_display_lock_ref[0] = True
        elif action == "APPEND_SUFFIX":
            text = _apply_append_suffix(text, param)
        elif action == "PREPEND_TEXT":
            text = _apply_prepend_text(text, param)
        elif action == "FORMAT_QTY":
            if qty_display_lock_ref[0]:
                if do_log:
                    debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: FORMAT_QTY) -> SKIP (qty_display_lock)")
                continue
            text = _apply_format_qty_single_stamp(text, param, qty, qty_display_lock_ref)

        text = re.sub(r"\s+", " ", str(text)).strip()
        if do_log:
            debug_log.append(f"Row {row_index} Rule #{rule_idx} (Action: {action}, Param: {repr(param)[:50]}) -> Matched? YES -> Result: {repr(text)[:50]}")

    final_weight = calculated_weight_ref[0]
    final_formatted = qty_display_lock_ref[0]  # True if any qty stamp was applied
    if not text:
        text = f" x{qty}ê°œ" if not final_formatted else " "
        text = text.strip() or f"{qty}ê°œ"
    return (text.strip(), final_weight, final_formatted)


def run_option_engine(df, option_rules, debug_log=None):
    # Column detection: Korean first, fallback to English (e.g. renamed headers)
    name_col = "ìƒí’ˆëª…" if "ìƒí’ˆëª…" in df.columns else ("Product Name" if "Product Name" in df.columns else None)
    option_col = "ì˜µì…˜ì •ë³´" if "ì˜µì…˜ì •ë³´" in df.columns else ("Option" if "Option" in df.columns else None)
    qty_col = "ìˆ˜ëŸ‰" if "ìˆ˜ëŸ‰" in df.columns else ("Qty" if "Qty" in df.columns else None)
    if not name_col:
        raise ValueError("ìƒí’ˆëª… ë˜ëŠ” 'Product Name' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì— ì œí’ˆëª… ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    if not option_col:
        raise ValueError("ì˜µì…˜ì •ë³´ ë˜ëŠ” 'Option' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì— ì˜µì…˜ ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    if not qty_col:
        raise ValueError("ìˆ˜ëŸ‰ ë˜ëŠ” 'Qty' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ì— ìˆ˜ëŸ‰ ì»¬ëŸ¼ì„ ì¶”ê°€í•˜ì„¸ìš”.")
    df = df.copy()
    df["_calculated_weight"] = 0.0
    df["_is_formatted"] = False
    df["_weight_calculated"] = False  # One-Shot Lock (per-row, used in apply_option_rules)
    # List-collection pattern (v14.1): collect in lists then assign once (faster than df.at[i] per row)
    opts = []
    weights = []
    formatted_flags = []
    for i in range(len(df)):
        row = df.iloc[i].copy()
        r_text, r_weight, r_fmt = apply_option_rules(
            row, option_rules, name_col, option_col, qty_col, row_index=i, debug_log=debug_log
        )
        opts.append(r_text)
        weights.append(r_weight)
        formatted_flags.append(r_fmt)
    df["processed_option"] = opts
    df["_calculated_weight"] = weights
    df["_is_formatted"] = formatted_flags
    return df


# ============== Step D: Merge & Sort ==============

def filter_instruction_rows(df):
    if df.empty:
        return df
    mask = df.astype(str).apply(
        lambda row: row.str.contains(FILTER_PHRASE, na=False).any(), axis=1
    )
    return df.loc[~mask].reset_index(drop=True)


def _cleanup_empty_parens(s):
    """Remove empty parentheses () or [] that might remain after removals."""
    if pd.isna(s) or not str(s).strip():
        return s
    t = str(s)
    t = re.sub(r"\(\s*\)", "", t)
    t = re.sub(r"\[\s*\]", "", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t


def merge_orders(df, option_rules=None):
    phone_col = DEFAULT_PHONE_COL if DEFAULT_PHONE_COL in df.columns else ALT_PHONE_COL
    if phone_col not in df.columns:
        raise ValueError("ì „í™”ë²ˆí˜¸ ì»¬ëŸ¼ ì—†ìŒ: ìˆ˜ì·¨ì¸ì—°ë½ì²˜1 ë˜ëŠ” êµ¬ë§¤ìì—°ë½ì²˜ í•„ìš”")
    group_cols = ["ìˆ˜ì·¨ì¸ëª…", phone_col, "í†µí•©ë°°ì†¡ì§€", "_VendorID"]
    for c in group_cols:
        if c not in df.columns:
            raise ValueError(f"ë³‘í•© í‚¤ ì»¬ëŸ¼ ì—†ìŒ: {c}")

    def join_options(ser):
        vals = ser.dropna().astype(str).str.strip()
        return " / ".join(v for v in vals if v)

    def join_unique_messages(ser):
        parts = ser.dropna().astype(str).str.strip().unique().tolist()
        return " / ".join(p for p in parts if p)

    agg_dict = {
        "processed_option": join_options,
        "ë°°ì†¡ë©”ì„¸ì§€": join_unique_messages,
        "_calculated_weight": "sum",
    }
    if "êµ¬ë§¤ìëª…" in df.columns:
        agg_dict["êµ¬ë§¤ìëª…"] = "first"
    if "ê²°ì œì¼" in df.columns:
        agg_dict["ê²°ì œì¼"] = "min"
    for col in df.columns:
        if col not in group_cols and col not in agg_dict:
            agg_dict[col] = "first"

    merged = df.groupby(group_cols, as_index=False).agg(agg_dict)

    # Weight Handling (FIX): Do NOT append total sum at end. Weights already per-item in Step C.
    merged["processed_option"] = merged["processed_option"].apply(_cleanup_empty_parens)
    return merged


def sort_by_payment_date(df):
    if "ê²°ì œì¼" not in df.columns or df.empty:
        return df
    df = df.copy()
    s = pd.to_datetime(df["ê²°ì œì¼"], errors="coerce")
    df["_sort_date"] = s
    df = df.sort_values("_sort_date", ascending=True, na_position="last").drop(columns=["_sort_date"])
    return df.reset_index(drop=True)


# ============== Step E: Export ==============

def build_output_dataframe(merged_df, output_layout, vendor_id):
    layout = output_layout[output_layout["VendorID"].astype(str).str.strip() == str(vendor_id).strip()]
    if layout.empty:
        return None
    layout = layout.sort_values("ExcelCol").reset_index(drop=True)
    row_count = len(merged_df)
    out = {}
    for _, r in layout.iterrows():
        header = str(r["HeaderName"]).strip() if pd.notna(r["HeaderName"]) else ""
        if not header:
            continue
        hc = r.get("HardcodedValue")
        if pd.notna(hc) and str(hc).strip():
            out[header] = [str(hc).strip()] * row_count
        else:
            src = r.get("SourceCol")
            if pd.notna(src) and str(src).strip() and str(src).strip() in merged_df.columns:
                out[header] = merged_df[str(src).strip()].values
            else:
                out[header] = [""] * row_count
    if not out:
        return None
    return pd.DataFrame(out)


def export_individual_files(merged_df, config):
    """Generate one Excel file per vendor. Returns list of {vendor, data, filename} (no ZIP)."""
    output_layout = config["OutputLayout"]
    vendor_ids = merged_df["_VendorID"].dropna().astype(str).str.strip().unique()
    vendor_ids = [v for v in vendor_ids if v and v != "Unclassified"]

    date_str = datetime.now().strftime("%Y%m%d")
    processed_files = []

    for vid in vendor_ids:
        subset = merged_df[merged_df["_VendorID"].astype(str).str.strip() == vid]
        layout = config["OutputLayout"]
        prefix_row = layout[layout["VendorID"].astype(str).str.strip() == vid]
        file_prefix = ""
        if not prefix_row.empty and "FilePrefix" in prefix_row.columns:
            file_prefix = str(prefix_row["FilePrefix"].iloc[0]).strip() if pd.notna(prefix_row["FilePrefix"].iloc[0]) else ""
        if file_prefix and str(file_prefix).lower().endswith(".xlsx"):
            file_prefix = str(file_prefix)[:-5]
        file_prefix = str(file_prefix).strip() if file_prefix else ""
        filename = f"{file_prefix}_{date_str}.xlsx" if file_prefix else f"{vid}_{date_str}.xlsx"

        out_df = build_output_dataframe(subset, layout, vid)
        if out_df is None or out_df.empty:
            out_df = subset.copy()
        excel_buf = BytesIO()
        with pd.ExcelWriter(excel_buf, engine="xlsxwriter") as writer:
            out_df.to_excel(writer, index=False, sheet_name="ë°œì£¼")
        excel_buf.seek(0)

        processed_files.append({
            "vendor": vid,
            "data": excel_buf,
            "filename": filename,
        })

    return processed_files


def process_all_data(df, config):
    """
    Full pipeline: filter -> route -> option rules -> [SORT by OrderNo] -> merge -> sort by date -> export.
    """
    product_route = config["ProductRoute"]
    option_rules = config["OptionRules"]
    
    # 1. í•„í„°ë§ (Filter)
    df = filter_instruction_rows(df)
    if df.empty:
        return []
    if "êµ¬ë§¤ìëª…" not in df.columns:
        df = df.copy()
        df["êµ¬ë§¤ìëª…"] = ""
        
    # 2. ì—…ì²´ ë¶„ë¥˜ (Routing)
    df = route_vendor(df, product_route)
    
    # 3. ë£° ì ìš© (Option Engine)
    df = run_option_engine(df, option_rules, debug_log=None)
    
    # =======================================================
    # â­â­ [NEW] ë³‘í•© ì „ ì •ë ¬ (Pre-Merge Sort) â­â­
    # ì„¤ëª…: 'ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸'ê°€ ìˆìœ¼ë©´ ì˜¤ë¦„ì°¨ìˆœ(1, 2, 3...)ìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•˜ë©´ ë’¤ì— merge_ordersê°€ ì‹¤í–‰ë  ë•Œ ì´ ìˆœì„œëŒ€ë¡œ ì˜µì…˜ì´ í•©ì³ì§‘ë‹ˆë‹¤.
    # =======================================================
    sort_col = "ìƒí’ˆì£¼ë¬¸ë²ˆí˜¸"
    if sort_col in df.columns:
        # ë°ì´í„° íƒ€ì…ì„ ë¬¸ìì—´ë¡œ í†µì¼í•´ì„œ ì •ë ¬ (ìˆ«ìì™€ ë¬¸ìê°€ ì„ì—¬ë„ ì—ëŸ¬ ì•ˆ ë‚˜ê²Œ)
        df[sort_col] = df[sort_col].astype(str)
        df = df.sort_values(by=sort_col, ascending=True)
    # =======================================================

    # 4. ë³‘í•© (Merge) - ì´ì œ ì •ë ¬ëœ ìˆœì„œëŒ€ë¡œ í•©ì³ì§!
    merged = merge_orders(df, option_rules=option_rules)
    
    # 5. ê²°ì œì¼ ê¸°ì¤€ ìµœì¢… ì •ë ¬ (Sort by Payment Date)
    if "ê²°ì œì¼" in merged.columns:
        merged = sort_by_payment_date(merged)
        
    # 6. íŒŒì¼ ìƒì„± (Export)
    return export_individual_files(merged, config)


# ============== UI (v14.3: Session State) ==============

def main():
    st.set_page_config(page_title="ì†ì´ˆ ë°œì£¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ v14.4", layout="wide")
    st.title("ì†ì´ˆ ë°œì£¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ v14.4")

    # Session state: persist processed results so download buttons do NOT trigger re-run
    if "processed_results" not in st.session_state:
        st.session_state.processed_results = None
    if "last_file_id" not in st.session_state:
        st.session_state.last_file_id = None

    st.write("ì„¤ì •: config.xlsx (ë¡œì»¬). ì£¼ë¬¸ íŒŒì¼ ì—…ë¡œë“œ í›„ Process ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

    if not HAS_MSOFFCRYPTO:
        st.warning("ë¹„ë°€ë²ˆí˜¸ ë³´í˜¸ ì—‘ì…€: `pip install msoffcrypto-tool`")

    config_path = "config.xlsx"
    try:
        path = Path(config_path).resolve()
        if not path.exists():
            st.error(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {path!s}")
            st.info("config.xlsxë¥¼ ì•±ê³¼ ê°™ì€ í´ë”ì— ë‘ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
        cache_key = f"{path.stat().st_mtime}_{path.stat().st_size}"
        config = load_config_local(config_path, _password="1111", _cache_key=cache_key)
    except FileNotFoundError as e:
        st.error(str(e))
        return
    except ValueError as e:
        st.error(str(e))
        return

    with st.sidebar:
        st.subheader("Config")
        st.caption("Config loaded from config.xlsx")

    uploaded_file = st.file_uploader("ì£¼ë¬¸ íŒŒì¼ (.xlsx ë˜ëŠ” .csv)", type=["xlsx", "csv"], key="uploaded_file")

    # When a new order file is uploaded (different name/size), reset processed_results
    if uploaded_file is not None:
        file_id = (uploaded_file.name, uploaded_file.size)
        if st.session_state.last_file_id != file_id:
            st.session_state.processed_results = None
            st.session_state.last_file_id = file_id

    # No file and no cached results -> ask to upload
    if uploaded_file is None and st.session_state.processed_results is None:
        st.info("ì£¼ë¬¸ íŒŒì¼ì„ ì—…ë¡œë“œí•œ ë’¤ 'Process Orders' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
        return

    # No file but we have results (e.g. after download click rerun) -> show download only
    if uploaded_file is None and st.session_state.processed_results is not None:
        st.success(f"ì²˜ë¦¬ ì™„ë£Œ. ì´ {len(st.session_state.processed_results)}ê°œ ì—…ì²´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        for i, pf in enumerate(st.session_state.processed_results):
            st.download_button(
                label=f"ğŸ“¥ Download [{pf['vendor']}] File",
                data=pf["data"].getvalue(),
                file_name=pf["filename"],
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"dl_{pf['vendor']}_{i}",
            )
        return

    # File uploaded: load and validate
    password = None
    if (uploaded_file.name or "").lower().endswith(".xlsx"):
        password = st.text_input("ì£¼ë¬¸ ì—‘ì…€ ë¹„ë°€ë²ˆí˜¸ (ì—†ìœ¼ë©´ ë¹„ì›€)", type="password", key="order_pw")
    file_name = (uploaded_file.name or "").lower()
    try:
        if file_name.endswith(".xlsx"):
            df = load_excel(uploaded_file, password=password)
        else:
            uploaded_file.seek(0)
            df = read_csv_with_encoding(uploaded_file)
    except Exception as e:
        st.error(str(e))
        return

    before = len(df)
    df = filter_instruction_rows(df)
    if before > len(df):
        st.info(f"ì•ˆë‚´ ë¬¸êµ¬ í–‰ {before - len(df)}ê°œ ì œê±°.")
    if df.empty:
        st.warning("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    required = ["ìˆ˜ëŸ‰", "ìƒí’ˆëª…", "ì˜µì…˜ì •ë³´", "ìˆ˜ì·¨ì¸ëª…", "í†µí•©ë°°ì†¡ì§€", "ë°°ì†¡ë©”ì„¸ì§€"]
    phone_ok = DEFAULT_PHONE_COL in df.columns or ALT_PHONE_COL in df.columns
    if not phone_ok:
        st.error("í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: ìˆ˜ì·¨ì¸ì—°ë½ì²˜1 ë˜ëŠ” êµ¬ë§¤ìì—°ë½ì²˜")
        return
    missing = [c for c in required if c not in df.columns]
    if missing and ("ìƒí’ˆëª…" not in df.columns or "ì˜µì…˜ì •ë³´" not in df.columns or "ìˆ˜ì·¨ì¸ëª…" not in df.columns or "í†µí•©ë°°ì†¡ì§€" not in df.columns):
        st.error("ìµœì†Œí•œ ìƒí’ˆëª…, ì˜µì…˜ì •ë³´, ìˆ˜ì·¨ì¸ëª…, í†µí•©ë°°ì†¡ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return

    st.subheader("Raw Data Preview (ìƒìœ„ 5í–‰)")
    st.dataframe(df.head())

    # Process button: run pipeline and store in session state
    if st.button("Process Orders"):
        with st.spinner("Processing..."):
            try:
                result = process_all_data(df, config)
                st.session_state.processed_results = result
                st.session_state.last_file_id = (uploaded_file.name, uploaded_file.size)
            except Exception as e:
                st.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                return
        st.rerun()

    # If we already have results for this session, show download section
    if st.session_state.processed_results is not None:
        st.success(f"ì²˜ë¦¬ ì™„ë£Œ. ì´ {len(st.session_state.processed_results)}ê°œ ì—…ì²´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
        for i, pf in enumerate(st.session_state.processed_results):
            st.download_button(
                label=f"ğŸ“¥ Download [{pf['vendor']}] File",
                data=pf["data"].getvalue(),
                file_name=pf["filename"],
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                key=f"dl_{pf['vendor']}_{i}",
            )
    else:
        st.caption("ìœ„ 'Process Orders' ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ì²˜ë¦¬ í›„ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ í‘œì‹œë©ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
